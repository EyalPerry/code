{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark:spark-sql_2.13:3.5.0`\n",
    "import $ivy.`org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.0`\n",
    "\n",
    "import $ivy.`org.apache.kafka:kafka-clients:3.5.1`\n",
    "import $ivy.`org.testcontainers:testcontainers:1.19.3`\n",
    "import $ivy.`org.testcontainers:kafka:1.19.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/30 16:30:51 INFO 5: Creating container for image: confluentinc/cp-kafka:7.6.5\n",
      "25/03/30 16:30:51 INFO 5: Container confluentinc/cp-kafka:7.6.5 is starting: 16ddc0d6a1f00a420518c1e79df70bae185aa88b6c9722bcf14f9e307f6a8c1c\n",
      "25/03/30 16:30:56 INFO 5: Container confluentinc/cp-kafka:7.6.5 started in PT4.245822057S\n",
      "25/03/30 16:30:56 INFO ProducerConfig: ProducerConfig values: \n",
      "\tacks = -1\n",
      "\tauto.include.jmx.reporter = true\n",
      "\tbatch.size = 16384\n",
      "\tbootstrap.servers = [PLAINTEXT://localhost:57629]\n",
      "\tbuffer.memory = 33554432\n",
      "\tclient.dns.lookup = use_all_dns_ips\n",
      "\tclient.id = producer-2\n",
      "\tcompression.type = none\n",
      "\tconnections.max.idle.ms = 540000\n",
      "\tdelivery.timeout.ms = 120000\n",
      "\tenable.idempotence = true\n",
      "\tinterceptor.classes = []\n",
      "\tkey.serializer = class org.apache.kafka.common.serialization.StringSerializer\n",
      "\tlinger.ms = 0\n",
      "\tmax.block.ms = 60000\n",
      "\tmax.in.flight.requests.per.connection = 5\n",
      "\tmax.request.size = 1048576\n",
      "\tmetadata.max.age.ms = 300000\n",
      "\tmetadata.max.idle.ms = 300000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tpartitioner.adaptive.partitioning.enable = true\n",
      "\tpartitioner.availability.timeout.ms = 0\n",
      "\tpartitioner.class = null\n",
      "\tpartitioner.ignore.keys = false\n",
      "\treceive.buffer.bytes = 32768\n",
      "\treconnect.backoff.max.ms = 1000\n",
      "\treconnect.backoff.ms = 50\n",
      "\trequest.timeout.ms = 30000\n",
      "\tretries = 2147483647\n",
      "\tretry.backoff.ms = 100\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.connect.timeout.ms = null\n",
      "\tsasl.login.read.timeout.ms = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.login.retry.backoff.max.ms = 10000\n",
      "\tsasl.login.retry.backoff.ms = 100\n",
      "\tsasl.mechanism = GSSAPI\n",
      "\tsasl.oauthbearer.clock.skew.seconds = 30\n",
      "\tsasl.oauthbearer.expected.audience = null\n",
      "\tsasl.oauthbearer.expected.issuer = null\n",
      "\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n",
      "\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n",
      "\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n",
      "\tsasl.oauthbearer.jwks.endpoint.url = null\n",
      "\tsasl.oauthbearer.scope.claim.name = scope\n",
      "\tsasl.oauthbearer.sub.claim.name = sub\n",
      "\tsasl.oauthbearer.token.endpoint.url = null\n",
      "\tsecurity.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tsend.buffer.bytes = 131072\n",
      "\tsocket.connection.setup.timeout.max.ms = 30000\n",
      "\tsocket.connection.setup.timeout.ms = 10000\n",
      "\tssl.cipher.suites = null\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.certificate.chain = null\n",
      "\tssl.keystore.key = null\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.certificates = null\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\ttransaction.timeout.ms = 60000\n",
      "\ttransactional.id = null\n",
      "\tvalue.serializer = class org.apache.kafka.common.serialization.StringSerializer\n",
      "\n",
      "25/03/30 16:30:56 INFO KafkaProducer: [Producer clientId=producer-2] Instantiated an idempotent producer.\n",
      "25/03/30 16:30:56 INFO AppInfoParser: Kafka version: 3.4.1\n",
      "25/03/30 16:30:56 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89\n",
      "25/03/30 16:30:56 INFO AppInfoParser: Kafka startTimeMs: 1743341456031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.kafka.clients.producer._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.testcontainers.containers.KafkaContainer\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.testcontainers.utility.DockerImageName\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.Properties\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@5daedaf9\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m\n",
       "\u001b[36mkafkaContainer\u001b[39m: \u001b[32mKafkaContainer\u001b[39m = GenericContainer(extraHosts=[], image=RemoteDockerImage(imageName=confluentinc/cp-kafka:7.6.5, imagePullPolicy=DefaultPullPolicy(), imageNameSubstitutor=org.testcontainers.utility.ImageNameSubstitutor$LogWrappedImageNameSubstitutor@9440958), volumesFroms=[], linkedContainers={}, startupCheckStrategy=org.testcontainers.containers.startupcheck.IsRunningStartupCheckStrategy@6f4ead4f, startupAttempts=1, workingDirectory=null, shmSize=null, copyToFileContainerPathMap={}, copyToTransferableContainerPathMap={}, dependencies=[], dockerClient=LazyDockerClient, containerId=16ddc0d6a1f00a420518c1e79df70bae185aa88b6c9722bcf14f9e307f6a8c1c, containerInfo=InspectContainerResponse(args=[-c, while [ ! -f /testcontainers_start.sh ]; do sleep 0.1; done; /testcontainers_start.sh], config=ContainerConfig(attachStderr=false, attachStdin=false, attachStdout=false, cmd=[-c, while [ ! -f /testcontainers_start.sh ]; do sleep 0.1; done; /testcontainers_start.sh], domainName=, entrypoint=[sh], env=[KAFKA_LOG_FLUSH_INTERVAL_MESSAGES=9223372036854775807, KAFKA_BROKER_ID=1, KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1, KAFKA_ZOOKEEPER_CONNECT=localhost:2181, KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS=1, KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1, KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9093,BROKER://0.0.0.0:9092, KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1, KAFKA_INTER_BROKER_LISTENER_NAME=BROKER, KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=BROKER:PLAINTEXT,PLAINTEXT:PLAINTEXT, KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0, PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin, container=oci, LANG=C.UTF-8, CUB_CLASSPATH=\"/usr/share/java/cp-base-new/*\", KAFKA_ADVERTISED_LISTENERS=, CLUSTER_ID=, COMPONENT=kafka], exposedPorts=[2181/tcp, 9092/tcp, 9093/tcp], hostName=16ddc0d6a1f0, image=confluentinc/cp-kafka:7.6.5, labels={architecture=x86_64, build-date=2025-01-21T14:25:54, com.redhat.component=ubi8-minimal-container, com.redhat.license_terms=https://www.redhat.com/en/about/red-hat-end-user-license-agreements#UBI, description=Common base image for Confluent's Docker images., desktop.docker.io/wsl-distro=Ubuntu-24.04, distribution-scope=public, io.buildah.version=1.33.8, io.confluent.docker=true, io.confluent.docker.build.number=361ed280, io.confluent.docker.git.id=0c8443c, io.confluent.docker.git.repo=confluentinc/kafka-images, io.k8s.description=The Universal Base Image Minimal is a stripped down image that uses microdnf as a package manager. This base image is freely redistributable, but Red Hat only supports Red Hat technologies through subscriptions for Red Hat products. This image is maintained by Red Hat and updated regularly., io.k8s.display-name=Red Hat Universal Base Image 8 Minimal, io.openshift.expose-services=, io.openshift.tags=minimal rhel8, maintainer=partner-support@confluent.io, name=cp-kafka, org.testcontainers=true, org.testcontainers.lang=java, org.testcontainers.sessionId=c4a6e4a3-e73f-42ef-81c5-64c0fcc15aa7, org.testcontainers.version=1.19.3, release=7.6.5-56, summary=Confluent platform Kafka., url=https://access.redhat.com/containers/#/registry.access.redhat.com/ubi8-minimal/images/8.10-1...\n",
       "\u001b[36mbootstrapServers\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"PLAINTEXT://localhost:57629\"\u001b[39m\n",
       "\u001b[36mkafkaProps\u001b[39m: \u001b[32mProperties\u001b[39m = {value.serializer=org.apache.kafka.common.serialization.StringSerializer, bootstrap.servers=PLAINTEXT://localhost:57629, key.serializer=org.apache.kafka.common.serialization.StringSerializer}\n",
       "\u001b[36mres5_11\u001b[39m: \u001b[32mObject\u001b[39m = \u001b[32mnull\u001b[39m\n",
       "\u001b[36mres5_12\u001b[39m: \u001b[32mObject\u001b[39m = \u001b[32mnull\u001b[39m\n",
       "\u001b[36mres5_13\u001b[39m: \u001b[32mObject\u001b[39m = \u001b[32mnull\u001b[39m\n",
       "\u001b[36mkafkaProducer\u001b[39m: \u001b[32mKafkaProducer\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mString\u001b[39m] = org.apache.kafka.clients.producer.KafkaProducer@3e972083\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36msendToKafka\u001b[39m\n",
       "\u001b[36mkafkaTopic\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"my-topic-scala\"\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.kafka.clients.producer._\n",
    "\n",
    "import org.testcontainers.containers.KafkaContainer\n",
    "import org.testcontainers.utility.DockerImageName\n",
    "import java.util.Properties\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"ScalaSpark\")\n",
    "  .master(\"local[*]\")\n",
    "  .getOrCreate()\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "val kafkaContainer = new KafkaContainer(\n",
    "  DockerImageName.parse(\"confluentinc/cp-kafka:7.6.5\")\n",
    ")\n",
    "\n",
    "kafkaContainer.start()\n",
    "\n",
    "val bootstrapServers = kafkaContainer.getBootstrapServers\n",
    "val kafkaProps = new Properties()\n",
    "kafkaProps.put(\"bootstrap.servers\", bootstrapServers)\n",
    "kafkaProps.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\")\n",
    "kafkaProps.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\")\n",
    "\n",
    "val kafkaProducer = new KafkaProducer[String, String](kafkaProps)\n",
    "\n",
    "def sendToKafka(topic: String, values: Seq[String]): Unit = {\n",
    " \n",
    "  values.foreach { value =>\n",
    "    val record = new ProducerRecord[String, String](topic, value)\n",
    "    kafkaProducer.send(record)\n",
    "  }\n",
    "  kafkaProducer.flush()\n",
    "}\n",
    "\n",
    "val kafkaTopic = \"my-topic-scala\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/30 16:30:59 WARN NetworkClient: [Producer clientId=producer-2] Error while fetching metadata with correlation id 5 : {my-topic-scala=LEADER_NOT_AVAILABLE}\n",
      "25/03/30 16:30:59 WARN NetworkClient: [Producer clientId=producer-2] Error while fetching metadata with correlation id 6 : {my-topic-scala=LEADER_NOT_AVAILABLE}\n",
      "25/03/30 16:30:59 INFO Metadata: [Producer clientId=producer-2] Resetting the last seen epoch of partition my-topic-scala-0 to 0 since the associated topicId changed from null to LG7PdRV8Q_SUxsS2cAKRig\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m\"a\"\u001b[39m, \u001b[32m\"b\"\u001b[39m, \u001b[32m\"c\"\u001b[39m, \u001b[32m\"d\"\u001b[39m, \u001b[32m\"e\"\u001b[39m)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = Seq(\"a\", \"b\", \"c\", \"d\", \"e\")\n",
    "\n",
    "sendToKafka(kafkaTopic, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/30 16:31:45 INFO CodeGenerator: Code generated in 9.704422 ms\n",
      "25/03/30 16:31:45 INFO CodeGenerator: Code generated in 18.34098 ms\n",
      "25/03/30 16:31:46 INFO AdminClientConfig: AdminClientConfig values: \n",
      "\tauto.include.jmx.reporter = true\n",
      "\tbootstrap.servers = [PLAINTEXT://localhost:57629]\n",
      "\tclient.dns.lookup = use_all_dns_ips\n",
      "\tclient.id = \n",
      "\tconnections.max.idle.ms = 300000\n",
      "\tdefault.api.timeout.ms = 60000\n",
      "\tmetadata.max.age.ms = 300000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\treceive.buffer.bytes = 65536\n",
      "\treconnect.backoff.max.ms = 1000\n",
      "\treconnect.backoff.ms = 50\n",
      "\trequest.timeout.ms = 30000\n",
      "\tretries = 2147483647\n",
      "\tretry.backoff.ms = 100\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.connect.timeout.ms = null\n",
      "\tsasl.login.read.timeout.ms = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.login.retry.backoff.max.ms = 10000\n",
      "\tsasl.login.retry.backoff.ms = 100\n",
      "\tsasl.mechanism = GSSAPI\n",
      "\tsasl.oauthbearer.clock.skew.seconds = 30\n",
      "\tsasl.oauthbearer.expected.audience = null\n",
      "\tsasl.oauthbearer.expected.issuer = null\n",
      "\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n",
      "\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n",
      "\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n",
      "\tsasl.oauthbearer.jwks.endpoint.url = null\n",
      "\tsasl.oauthbearer.scope.claim.name = scope\n",
      "\tsasl.oauthbearer.sub.claim.name = sub\n",
      "\tsasl.oauthbearer.token.endpoint.url = null\n",
      "\tsecurity.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tsend.buffer.bytes = 131072\n",
      "\tsocket.connection.setup.timeout.max.ms = 30000\n",
      "\tsocket.connection.setup.timeout.ms = 10000\n",
      "\tssl.cipher.suites = null\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.certificate.chain = null\n",
      "\tssl.keystore.key = null\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.certificates = null\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\n",
      "25/03/30 16:31:46 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.\n",
      "25/03/30 16:31:46 INFO AppInfoParser: Kafka version: 3.4.1\n",
      "25/03/30 16:31:46 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89\n",
      "25/03/30 16:31:46 INFO AppInfoParser: Kafka startTimeMs: 1743341506103\n",
      "25/03/30 16:31:46 INFO AppInfoParser: App info kafka.admin.client for adminclient-1 unregistered\n",
      "25/03/30 16:31:46 INFO Metrics: Metrics scheduler closed\n",
      "25/03/30 16:31:46 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter\n",
      "25/03/30 16:31:46 INFO Metrics: Metrics reporters closed\n",
      "25/03/30 16:31:46 INFO KafkaRelation: GetBatch generating RDD of offset range: KafkaOffsetRange(my-topic-scala-0,-2,-1,None)\n",
      "25/03/30 16:31:46 INFO CodeGenerator: Code generated in 11.612321 ms\n",
      "25/03/30 16:31:46 INFO CodeGenerator: Code generated in 6.871033 ms\n",
      "25/03/30 16:31:46 INFO SparkContext: Starting job: show at cmd7.sc:8\n",
      "25/03/30 16:31:46 INFO DAGScheduler: Got job 2 (show at cmd7.sc:8) with 1 output partitions\n",
      "25/03/30 16:31:46 INFO DAGScheduler: Final stage: ResultStage 3 (show at cmd7.sc:8)\n",
      "25/03/30 16:31:46 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/03/30 16:31:46 INFO DAGScheduler: Missing parents: List()\n",
      "25/03/30 16:31:46 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at show at cmd7.sc:8), which has no missing parents\n",
      "25/03/30 16:31:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 31.5 KiB, free 2.2 GiB)\n",
      "25/03/30 16:31:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KiB, free 2.2 GiB)\n",
      "25/03/30 16:31:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.255.255.254:46069 (size: 11.2 KiB, free: 2.2 GiB)\n",
      "25/03/30 16:31:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580\n",
      "25/03/30 16:31:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at show at cmd7.sc:8) (first 15 tasks are for partitions Vector(0))\n",
      "25/03/30 16:31:46 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "25/03/30 16:31:46 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6) (10.255.255.254, executor driver, partition 0, PROCESS_LOCAL, 7883 bytes) \n",
      "25/03/30 16:31:46 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)\n",
      "25/03/30 16:31:46 INFO ConsumerConfig: ConsumerConfig values: \n",
      "\tallow.auto.create.topics = true\n",
      "\tauto.commit.interval.ms = 5000\n",
      "\tauto.include.jmx.reporter = true\n",
      "\tauto.offset.reset = none\n",
      "\tbootstrap.servers = [PLAINTEXT://localhost:57629]\n",
      "\tcheck.crcs = true\n",
      "\tclient.dns.lookup = use_all_dns_ips\n",
      "\tclient.id = consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1\n",
      "\tclient.rack = \n",
      "\tconnections.max.idle.ms = 540000\n",
      "\tdefault.api.timeout.ms = 60000\n",
      "\tenable.auto.commit = false\n",
      "\texclude.internal.topics = true\n",
      "\tfetch.max.bytes = 52428800\n",
      "\tfetch.max.wait.ms = 500\n",
      "\tfetch.min.bytes = 1\n",
      "\tgroup.id = spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor\n",
      "\tgroup.instance.id = null\n",
      "\theartbeat.interval.ms = 3000\n",
      "\tinterceptor.classes = []\n",
      "\tinternal.leave.group.on.close = true\n",
      "\tinternal.throw.on.fetch.stable.offset.unsupported = false\n",
      "\tisolation.level = read_uncommitted\n",
      "\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\tmax.partition.fetch.bytes = 1048576\n",
      "\tmax.poll.interval.ms = 300000\n",
      "\tmax.poll.records = 500\n",
      "\tmetadata.max.age.ms = 300000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]\n",
      "\treceive.buffer.bytes = 65536\n",
      "\treconnect.backoff.max.ms = 1000\n",
      "\treconnect.backoff.ms = 50\n",
      "\trequest.timeout.ms = 30000\n",
      "\tretry.backoff.ms = 100\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.connect.timeout.ms = null\n",
      "\tsasl.login.read.timeout.ms = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.login.retry.backoff.max.ms = 10000\n",
      "\tsasl.login.retry.backoff.ms = 100\n",
      "\tsasl.mechanism = GSSAPI\n",
      "\tsasl.oauthbearer.clock.skew.seconds = 30\n",
      "\tsasl.oauthbearer.expected.audience = null\n",
      "\tsasl.oauthbearer.expected.issuer = null\n",
      "\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n",
      "\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n",
      "\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n",
      "\tsasl.oauthbearer.jwks.endpoint.url = null\n",
      "\tsasl.oauthbearer.scope.claim.name = scope\n",
      "\tsasl.oauthbearer.sub.claim.name = sub\n",
      "\tsasl.oauthbearer.token.endpoint.url = null\n",
      "\tsecurity.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tsend.buffer.bytes = 131072\n",
      "\tsession.timeout.ms = 45000\n",
      "\tsocket.connection.setup.timeout.max.ms = 30000\n",
      "\tsocket.connection.setup.timeout.ms = 10000\n",
      "\tssl.cipher.suites = null\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.certificate.chain = null\n",
      "\tssl.keystore.key = null\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.certificates = null\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\n",
      "25/03/30 16:31:46 INFO AppInfoParser: Kafka version: 3.4.1\n",
      "25/03/30 16:31:46 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89\n",
      "25/03/30 16:31:46 INFO AppInfoParser: Kafka startTimeMs: 1743341506418\n",
      "25/03/30 16:31:46 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Assigned to partition(s): my-topic-scala-0\n",
      "25/03/30 16:31:46 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Seeking to earliest offset of partition my-topic-scala-0\n",
      "25/03/30 16:31:46 INFO Metadata: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Resetting the last seen epoch of partition my-topic-scala-0 to 0 since the associated topicId changed from null to LG7PdRV8Q_SUxsS2cAKRig\n",
      "25/03/30 16:31:46 INFO Metadata: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Cluster ID: cZ50csZwQJq5DV0_W8WMsw\n",
      "25/03/30 16:31:46 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Resetting offset for partition my-topic-scala-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:57629 (id: 1 rack: null)], epoch=0}}.\n",
      "25/03/30 16:31:46 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Seeking to latest offset of partition my-topic-scala-0\n",
      "25/03/30 16:31:46 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Resetting offset for partition my-topic-scala-0 to position FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:57629 (id: 1 rack: null)], epoch=0}}.\n",
      "25/03/30 16:31:46 INFO CodeGenerator: Code generated in 14.403349 ms\n",
      "25/03/30 16:31:46 INFO CodeGenerator: Code generated in 17.200472 ms\n",
      "25/03/30 16:31:46 INFO CodeGenerator: Code generated in 6.518902 ms\n",
      "25/03/30 16:31:46 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Seeking to offset 0 for partition my-topic-scala-0\n",
      "25/03/30 16:31:46 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Seeking to earliest offset of partition my-topic-scala-0\n",
      "25/03/30 16:31:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Resetting offset for partition my-topic-scala-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:57629 (id: 1 rack: null)], epoch=0}}.\n",
      "25/03/30 16:31:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Seeking to latest offset of partition my-topic-scala-0\n",
      "25/03/30 16:31:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor-1, groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor] Resetting offset for partition my-topic-scala-0 to position FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:57629 (id: 1 rack: null)], epoch=0}}.\n",
      "25/03/30 16:31:47 INFO CodeGenerator: Code generated in 32.500037 ms\n",
      "25/03/30 16:31:47 INFO KafkaDataConsumer: From Kafka topicPartition=my-topic-scala-0 groupId=spark-kafka-relation-a864622f-267a-431d-9bf1-404c90dad4e6-executor read 5 records through 1 polls (polled  out 5 records), taking 614965233 nanos, during time span of 787040184 nanos.\n",
      "25/03/30 16:31:47 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 1673 bytes result sent to driver\n",
      "25/03/30 16:31:47 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 906 ms on 10.255.255.254 (executor driver) (1/1)\n",
      "25/03/30 16:31:47 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "25/03/30 16:31:47 INFO DAGScheduler: ResultStage 3 (show at cmd7.sc:8) finished in 0.935 s\n",
      "25/03/30 16:31:47 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/03/30 16:31:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "25/03/30 16:31:47 INFO DAGScheduler: Job 2 finished: show at cmd7.sc:8, took 0.940341 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|message|\n",
      "+-------+\n",
      "|      a|\n",
      "|      b|\n",
      "|      c|\n",
      "|      d|\n",
      "|      e|\n",
      "+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [message: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", bootstrapServers)\n",
    "  .option(\"subscribe\", kafkaTopic)\n",
    "  .load()\n",
    "  .selectExpr(\"CAST(value AS STRING) as message\")\n",
    "\n",
    "  df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
